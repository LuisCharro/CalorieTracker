Transcript:
I gave myself one week to take this
prototype and make it a fully
functioning app that people could use.
Clock started Monday morning and this is
what happened. So last week I built
this. It's a prototype for an app called
Amy, which is a calorie tracking app in
the style of Apple Notes. You type the
food you ate on the left and then on the
right the app is going to search and
find the calories for you. I made it in
12 hours just to experiment with some
new technology. I posted online and
honestly the response was kind of
insane. I got hundreds of replies.
Dozens of very talented designers said
that the app looked pretty cool and over
500 people ended up joining the wait
list. I have been building apps for
years and I'm constantly posting
concepts and project updates all the
time. But the response I got for this
app was very rare. And when people care
this much about something, you don't let
that opportunity go to waste. There was
just one problem though. This was not a
real app. It was just a prototype that
was built in 12 hours. There's no
database. There's no backend. There
really were no other features aside from
the one that I posted in the initial
screenshot. What I decided to do to make
sure that this opportunity does not go
to waste was build the app and make it
fully functioning in just one week and
then onboard the first set of users so I
can start getting feedback. And that's
what we're going to be covering in this
video. I'm going to show you everything
I did to go from this concept to
actually submitting the app on test
flight so that the first couple of users
can start using it. If you're new here,
welcome to the channel. My name is Chris
and I build productivity apps and I try
to document everything that I'm learning
and share it with you guys on this
channel.
[Music]
So, the first thing that I did was
actually stabilize the app. I did have
the prototype and it looked really good.
You can type things and the AI worked.
Everything was functional except it
really was not that stable. This is one
of those things that looks really simple
on the surface, but there's a lot of
complex things going on behind the
scenes. For example, the way I built
this is it's actually two scroll views.
One on the left that has the text editor
and then one on the right that has the
calories and they're constantly in sync.
So, one example of a problem that I was
facing was there were some cases where
those two scroll views would actually
get out of sync. So, I actually had to
rewrite this thing a couple times and
then there were some little things like
what if you have multi-line text? How is
it going to push all the other stuff at
the bottom? And then obviously there
were some edge cases like what if the
device went offline? What if the server
had a bad response or was taking too
long? So, I spent the first day just
trying to make sure that this core
interaction was absolutely bulletproof.
To be honest, the AI part was actually
already solid. If you saw my last video,
you know I'm using Perplexity Sonar to
actually power the AI and the database
search for the app. And honestly, it
does most of the heavy lifting. There
really isn't much I need to do in terms
of accuracy here. The AI is not the hard
part of this app. It's actually the UI
and the UX and making sure that this is
a very good experience for the user and
something that they actually stick with.
Nailing the core experience down to all
of the animations took an entire day,
but it was absolutely worth it.
[Music]
Day two and three I spent working on the
nutrition detail page. When I created
the prototype of this app, it was really
just to learn Apple's liquid glass and
their foundation model. So, there were
no secondary pages. And this nutrition
detail page, which is the page that
appears when you click the calories on
the right and shows you the breakdown of
the nutrition. That is a very important
secondary page. So, it didn't exist. Had
to completely create it from scratch.
Did use cloud code and quickly
prototyped a very basic one, but
honestly, it did not look good. So, I
cheated a little bit and asked my
fiance√© Cecilia to help me design a
better one. So, we spent two whole days
trying to figure out what would make
this page really good. She has a whole
video on her channel breaking down the
designs of this and all the iterations
we did. But, there was a lot of things
like I think we tested like 15 different
background colors, a bunch of different
layouts. Something to highlight though
was the thing we wanted to capture in
this page was trust. Because a problem
with a lot of these calorie tracking
apps is users need to trust the data
behind them, especially when the
calories are being calculated manually.
So the first thought was, okay, if I at
least have a breakdown of the individual
items and the nutrients, maybe that's
enough. But after sitting with it for a
few hours, I honestly didn't really
trust it that much. So the next thing we
added were the ability to see the
sources. So these were the individual
web pages that the AI looked through to
get this data. That did really make a
big difference and help because when I
saw the nutrients, I'm like, "Okay, at
least I know where this came from." But
it still wasn't good enough. So then we
added one final thing, which was this
section called Amy's thought process.
And this actually made a huge difference
because it's a section where Amy will
tell you how it came up with the calorie
calculation. So if it used specific
substitutes or calculated the portions
in a different way, you can see the
breakdown here. And this made such a big
difference in terms of me trusting the
data. So now every time I click on a
calorie, I actually go and I read the
thought process. And if I like what I
see, I'm like, "Okay, cool. I trust the
data." And if I don't, I usually then
can just close out and then just re-edit
it and be like, "I need to be more
specific with the portions or
something." This was the thought process
that went into this page. Our northstar
here was, does it make us trust the
underlying calories that it's
calculating? And I actually think that
it really did. Sadly, there was
something we had to cut. I wanted the
ability to edit the calories on this
page. So, I was hoping we can have a
button floating at the bottom where when
you click it, you can then start
chatting with an AI and tell it, "Hey,
this seems a little overestimated or you
use the wrong thing." And it would go
make edits. I did make a little bit of
progress there. Unfortunately, I think
it would take me probably a few extra
days to make sure that this functioned
perfectly. So, I completely scrapped it
for now from the beta. Since this is
such a simple app and there's really
only like three pages and this is one of
those pages, it was worth it in my
opinion to spend two whole days really
perfecting it. And now it's a page that
I absolutely love opening.
[Music]
The next day, I decided to work on the
goals feature. So, something I quickly
realized after just using it for a few
days myself was I needed the ability to
set a specific goal, whether it be a
calorie goal or a protein goal or
something. Because right now, the app is
just a calorie tracker. And people don't
track calories just for the sake of
tracking calories. They're usually
tracking calories because they want to
hit a specific goal. They want to lose
weight. They want to gain muscle. They
want to do something. So, I knew that
this was a very important feature I
needed to have early on. Originally, we
had this bar at the bottom that showed
the total calories for the day.
completely swapped it with a new one
where when you click it, it'll show you
a bunch of different bars. So, you can
see how many calories you have left, how
many how much protein, how much fat, how
much carbs. You can see this in a really
glancible way. Now, there's a new
settings page where you can specify what
your goal is, whether you want to lose
weight or gain weight or maintain. And
then you can set the different
macronutrient and calorie targets there.
And I added this cool thing where if
you're not sure what the targets should
be, you can click it and then if you
answer a couple of these questions, it's
going to use AI and actually generate
what the target should be for you. Still
a lot of refinement on that to be
honest, but I was really happy with how
it came out. And this will also be a
really important screen during the
onboarding. Next, I decided to add
notifications. And the reason is based
on my experience building apps,
notifications are a very powerful way to
get people to build habits. And
something like a food journal/coral
tracking app like this, building that
habit of logging is extremely important.
Features super basic right now, but I
decided to support the ability to get
two notifications, three or five every
single day. I'm definitely going to
enhance this. I'll probably let people
personalize this so they can choose what
time they wanted, how much frequency,
but this was actually really quick to
implement since it's a very simplified
version, but really glad I was able to
ship this one, too.
A5 was working on little refinements.
One of the small refinements that that
actually made a pretty big difference
was using location in the app. You can
actually turn on location in the app and
the AI will now use this when it's
trying to calculate calories. So, what
does this mean? I'll give you an
example. Let's say you type in two
cocktails from Laurel. It has absolutely
no idea what Laurel is without the
location data. And so it's probably just
going to try to find a restaurant
somewhere or maybe it's a brand and it's
going to use that when estimating the
calories. With location data on now, I
can pass this into the AI and you'll see
that the results are actually way
better. Let's say I'm in San Francisco
and I type two cocktails from Laurel. It
correctly now knows that I'm talking
about true Laurel cocktail bar in San
Francisco. And you can see this in the
new Amy's thought process section, which
is really, really cool. I think this is
going to be a very big magic moment for
people, just like it was for me when I
first saw that. So, that was a really
small refinement I added. Next
refinement was I decided to build in
dictation into the app. As I was using
the app, I found myself wanting to just
dictate rather than type into the app
because realistically, it'll let me get
way more detailed with what I'm typing.
So, I thought really hard about this.
Tried a bunch of different design
patterns. And this is the one I ended up
settling on. The bar where we have the
goals for the user. I decided to
actually put the dictation and
specifically the little tick marks that
appear as the volume changes as the user
speaking. I decided to put it there. And
to make it feel really premium, this is
all custom animation. So the ticks
moving as the user's talking and getting
larger and smaller. Completely custom.
I'll slow it down here. But if you look
at the accept and the cancel buttons, it
actually is a custom animation where the
icons themselves are animating in and
out. And if you're curious how I did
this, I'm using Apple's SF symbols. And
this is actually an animation that comes
default when you use some of this stuff.
It's like two lines of code. Since
there's not many features in here, I
needed to make sure every single
interaction and animation was a home run
and just felt so premium. Okay, so I
know I've been talking about dictation
in my own app. But let me tell you where
I came up with the inspiration for this
and it's because I've been using an app
called Whisper Flow. If you've been
following my channel for a while, you
know that I've been dictating absolutely
everything. It is just so much faster
than typing. And Whisper Flow is the
best dictation tool that I have found.
And a huge shout out to them for
actually being a channel sponsor. My
recommendation is to just use Whisper
Flow when you're dictating into my own
app. But if you can't, for some reason,
just use the one that I built into the
app that we've been talking about. I'm
using Apple's native dictation library
to power that dictation feature, but
it's just not as accurate as something
specialized like Whisper Flow. Here's an
example. If I say something really quick
like chicken pad thai with no bean
sprouts, you can see in my app sometimes
it has a hard time picking it up,
especially if I'm speaking quickly. But
if I say the exact same thing using
whisper flow. So if I say chicken pad
thai no bean sprouts,
it perfectly gets it. It is just so much
more accurate. And this is just a limit
of Apple's native dictation that I'm
using to power the dictation in my app.
Whisperflow also lets you create a
personalized dictionary of terms and
phrases, which makes it way more
accurate if you're using words that are
not commonly used. I use it for
everything. Dictating into Claude code,
writing emails, sending text through
their iOS app. I even write all my
YouTube scripts by dictating into
Claude, which saves me at least 30
minutes every single time. And it works
across all apps on desktop and iOS, not
just inside a single tool. I'll leave a
link in the description below. And
there's a code for 1 month free on top
of the 14-day trial that you already get
when you sign up. They did not have to
provide that code. I'm the one that
asked for that. So, a huge shout out to
them for doing that. Location tracking
and dictation. This is what I worked on
on day five. And they might seem really
small, but I think they're going to add
up and make this a very good experience.
Day six, finally hooked up a backend and
database. So up to this point, if you
killed the app and reopened it, all the
data would be gone. Once I sorted out
the UI, the UX, and I kind of figured
out what data structure I wanted. I
quickly spun up a database to persist
the data and then a backend to go along
with it. For database, I'm using a
service called Superbase, which I'm sure
a lot of you guys have already heard
about. Here's where I'm going to say
something controversial. I actually use
something called Superbase MCP, which is
an MCP server you can give to something
like Claude Code. So now claude code
which is a coding agent has complete
access to my superbase account to spin
up databases and just do everything I
can do in the UI. The reason it's
controversial is because it is pretty
dangerous to do this. So I already know
a lot of developers are going to be
probably commenting being like why are
you doing that? This is really unsafe.
They are totally right. But in my
opinion I think it is completely fine to
use stuff like this especially early on
when there's no real data, there's no
real users to quickly spin up and
scaffold a project for you. It was able
to spin up the entire database structure
in about like 10 minutes. And this is
something that usually takes me a few
hours to do correctly. I love to use MCP
database tools like this. But then
obviously when the app's in production,
that's when I usually stop using stuff
like this or use them in just readonly
mode for debugging because it does get a
little more risky when you're dealing
with real user data. So I try to be a
little bit more careful there. In terms
of the back end, it's a very simple Node
Express server. So there's really not
much to talk about there. There's just a
few endpoints hosted there for the AI
stuff. But I do want to call this out
because this is something I see with a
lot of people who build mobile apps is
they usually build the AI directly into
the mobile app. Do not do this. That is
very insecure. The proper way to do this
is you want to put the AI on some sort
of backend service and then call that
from your mobile app. You never want the
front-end service to call OpenAI,
Enthropic, Open Router directly. You
want to do that through a backend
service just because it is way more
secure. So I took the database, the back
end, hooked it up to the iOS app, and
now it is basically complete at this
point. I think because I've spun these
things up so many times, this was really
easy. So, it actually took less than a
day to do this.
And on the final day, the last thing I
worked on was the AI abuse protection
stuff. Because there is AI being used
here, it is very important to make sure
you have protections in place before you
launch this thing to real users. And
that's because this stuff can get really
expensive. someone could intentionally
or even non-intentionally because of a
bug accidentally rack up $10,000 in AI
costs. I'll talk about some of the
protections I put in place, but the big
ones are I put daily, weekly, and
monthly limits on each of the users
accounts, completely invisible to them.
They can't see what the limits are, but
there are limits there. So, if for some
day they try to type 1,000 foods in a
single day, they will get an alert
saying that they hit a daily limit and
to contact support. These are very
reasonable limits that I don't think
normal people should hit. And if they
are for some reason and they reach out
to me, that's really good for me to know
to figure out is there something wrong
on my end or are they using it in a way
that I just didn't think of. So there
are those limits in place. They live on
the back end. It's very secure. I also
added a kill switch. So on the user's
account, I can turn off the AI features
completely. So if for some reason I see
a user racking up a bunch of AI bills
and I'm like, "Okay, this needs to stop.
I need to figure out what's going on." I
can turn it off remotely on my end and
then they just can't access any of the
AI functions at all. And then I had some
cost tracking with Post Hog LLM
analytics. But I'll probably make a
whole video on how I'm protecting this
app on the AI front because that is a
common question that I'm constantly
getting. So if you want to see a video
like that, please leave a comment below
and I can go way more in depth in how I
set all this stuff up. And that was
actually the week and I submitted it to
TestFlight and we got approved by Apple
and I was able to onboard the first five
beta testers. A week ago, I had this
prototype with literally no intentions
of building an actual app. And today, we
have a fully functioning app with what I
believe are really good features. And we
have five users actually on boarded and
using this thing right now. I think this
is a pretty rare opportunity. So, I
wanted to make sure even though I am
working on a bunch of stuff to make time
this week to try to iterate and progress
on this app and thankfully I was able to
do it. Next step is to get the feedback
from these five beta testers and then
hopefully onboard the next 100 beta
testers. So, if you haven't joined the
weight list yet, the link in the
description for that below. And we're
going to keep iterating on this app.
We're going to try to figure out what
the pricing is supposed to be. We're
going to try to get our first paid
users. And I'm very excited to take you
guys along with me. If there's something
specific you want me to cover, please
leave a comment below. And if you like
this kind of content, check out my
Instagram and Tik Tok. I'm posting
almost every other day about building
this app specifically. There's a lot of
cool stuff behind the scenes on my
Instagram page. And obviously, if you
like this content, don't forget to
subscribe. But thank you guys so much
for watching, and I will see you guys in
the next video.
[Music]
